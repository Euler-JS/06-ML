# Importar bibliotecas necess√°rias
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Adicionados: import para carregar de forma robusta
import os
from pathlib import Path

# ==========================
# 1. CARREGAR DADOS
# ==========================
print("=" * 60)
print("AN√ÅLISE DO DATASET TITANIC - REGRESS√ÉO LINEAR")
print("=" * 60)

# Carregar o dataset (antes: pd.read_csv('TitanicDataset.csv'))
def load_dataset(candidates=None):
    base = Path(__file__).resolve().parent
    if candidates is None:
        candidates = [
            "Titanic-Dataset.csv",
            "TitanicDataset.csv",
            "Titanic-Dataset .csv",
            "titanic-dataset.csv",
            "titanicdataset.csv"
        ]
    # 1) procurar na mesma pasta do script
    for name in candidates:
        p = base / name
        if p.exists():
            return pd.read_csv(p)
    # 2) procurar no cwd
    for name in candidates:
        p = Path.cwd() / name
        if p.exists():
            return pd.read_csv(p)
    # 3) procurar qualquer CSV com 'titanic' no nome (script dir e cwd)
    for p in list(base.glob("*.csv")) + list(Path.cwd().glob("*.csv")):
        if "titanic" in p.name.lower():
            return pd.read_csv(p)
    # 4) falha com mensagem √∫til
    files_script = ", ".join([f.name for f in base.iterdir()])
    files_cwd = ", ".join([f.name for f in Path.cwd().iterdir()])
    raise FileNotFoundError(
        f"Dataset n√£o encontrado. Procurei em:\n  script dir: {base}\n  cwd: {Path.cwd()}\n\n"
        f"Arquivos no script dir: {files_script}\nArquivos no cwd: {files_cwd}\n\n"
        "Coloque o arquivo 'Titanic-Dataset.csv' na pasta do projeto ou no diret√≥rio atual."
    )

df = load_dataset()

print("\nüìä Primeiras linhas do dataset:")
print(df.head())

print(f"\nüìè Dimens√µes: {df.shape[0]} linhas x {df.shape[1]} colunas")

# ==========================
# 2. AN√ÅLISE EXPLORAT√ìRIA
# ==========================
print("\n" + "=" * 60)
print("AN√ÅLISE EXPLORAT√ìRIA DOS DADOS")
print("=" * 60)

print("\nüîç Informa√ß√µes do dataset:")
print(df.info())

print("\nüìà Estat√≠sticas descritivas:")
print(df.describe())

print("\n‚ùì Valores nulos:")
print(df.isnull().sum())

print("\nüìä Estat√≠sticas da vari√°vel alvo (Fare):")
print(f"M√©dia: ${df['Fare'].mean():.2f}")
print(f"Mediana: ${df['Fare'].median():.2f}")
print(f"Desvio padr√£o: ${df['Fare'].std():.2f}")
print(f"M√≠nimo: ${df['Fare'].min():.2f}")
print(f"M√°ximo: ${df['Fare'].max():.2f}")

print("\nüìä Tarifa m√©dia por Classe:")
print(df.groupby('Pclass')['Fare'].mean().sort_values(ascending=False))

print("\nüìä Tarifa m√©dia por Sexo:")
print(df.groupby('Sex')['Fare'].mean())

# ==========================
# 3. PR√â-PROCESSAMENTO
# ==========================
print("\n" + "=" * 60)
print("PR√â-PROCESSAMENTO DOS DADOS")
print("=" * 60)

# Criar c√≥pia para processamento
df_processed = df.copy()

# Remover linhas onde Fare √© nulo (vari√°vel alvo)
print(f"\nüîß Removendo linhas com Fare nulo...")
print(f"Linhas antes: {len(df_processed)}")
df_processed = df_processed[df_processed['Fare'].notna()]
print(f"Linhas depois: {len(df_processed)}")

# Preencher valores nulos nas features
print("\nüîß Tratando valores nulos nas features...")
df_processed['Age'].fillna(df_processed['Age'].median(), inplace=True)
df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0], inplace=True)

print("Valores nulos ap√≥s tratamento:")
print(df_processed.isnull().sum())

# Remover coluna Cabin (muitos nulos)
if 'Cabin' in df_processed.columns:
    df_processed.drop('Cabin', axis=1, inplace=True)

# Codificar vari√°veis categ√≥ricas
print("\nüîß Codificando vari√°veis categ√≥ricas...")
le_sex = LabelEncoder()
df_processed['Sex'] = le_sex.fit_transform(df_processed['Sex'])

if 'Embarked' in df_processed.columns:
    le_embarked = LabelEncoder()
    df_processed['Embarked'] = le_embarked.fit_transform(df_processed['Embarked'])

# Criar novas features
print("üîß Criando novas features...")
df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1
df_processed['IsAlone'] = (df_processed['FamilySize'] == 1).astype(int)

print(f"FamilySize - Min: {df_processed['FamilySize'].min()}, Max: {df_processed['FamilySize'].max()}")
print(f"IsAlone - Distribui√ß√£o:\n{df_processed['IsAlone'].value_counts()}")

# Selecionar features para o modelo
features_to_use = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Survived', 'FamilySize', 'IsAlone']
if 'Embarked' in df_processed.columns:
    features_to_use.append('Embarked')

X = df_processed[features_to_use]
y = df_processed['Fare']

print(f"\n‚úÖ Features selecionadas: {features_to_use}")
print(f"‚úÖ Vari√°vel alvo: Fare (Tarifa)")
print(f"‚úÖ Shape dos dados: X={X.shape}, y={y.shape}")

# ==========================
# 4. DIVIS√ÉO TREINO/TESTE
# ==========================
print("\n" + "=" * 60)
print("DIVIS√ÉO DOS DADOS")
print("=" * 60)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nüìä Tamanho do conjunto de treino: {X_train.shape[0]} amostras")
print(f"üìä Tamanho do conjunto de teste: {X_test.shape[0]} amostras")
print(f"\nEstat√≠sticas da tarifa no treino:")
print(f"  M√©dia: ${y_train.mean():.2f}")
print(f"  Mediana: ${y_train.median():.2f}")
print(f"\nEstat√≠sticas da tarifa no teste:")
print(f"  M√©dia: ${y_test.mean():.2f}")
print(f"  Mediana: ${y_test.median():.2f}")

# Normalizar os dados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\n‚úÖ Dados normalizados com StandardScaler")

# ==========================
# 5. TREINAMENTO DOS MODELOS
# ==========================
print("\n" + "=" * 60)
print("TREINAMENTO DOS MODELOS DE REGRESS√ÉO")
print("=" * 60)

# Dicion√°rio de modelos
models = {
    'Linear Regression': LinearRegression(),
    'Ridge Regression': Ridge(alpha=1.0, random_state=42),
    'Lasso Regression': Lasso(alpha=1.0, random_state=42)
}

results = {}

for name, model in models.items():
    print(f"\nüöÄ Treinando {name}...")
    
    # Treinar modelo
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    
    # Cross-validation (R¬≤ score negativo no sklearn)
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
    
    # Calcular m√©tricas
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    results[name] = {
        'model': model,
        'predictions': y_pred,
        'mse': mse,
        'rmse': rmse,
        'mae': mae,
        'r2': r2,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std()
    }
    
    print(f"‚úÖ MSE (Mean Squared Error): {mse:.4f}")
    print(f"‚úÖ RMSE (Root Mean Squared Error): ${rmse:.2f}")
    print(f"‚úÖ MAE (Mean Absolute Error): ${mae:.2f}")
    print(f"‚úÖ R¬≤ Score: {r2:.4f}")
    print(f"üìä Cross-validation R¬≤ (5-fold): {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

# ==========================
# 6. AVALIA√á√ÉO DOS MODELOS
# ==========================
print("\n" + "=" * 60)
print("AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS")
print("=" * 60)

# Comparar modelos
print("\nüìä Resumo dos Resultados:")
print("-" * 80)
print(f"{'Modelo':<20} {'RMSE':<12} {'MAE':<12} {'R¬≤':<12} {'CV R¬≤':<15}")
print("-" * 80)
for name, result in sorted(results.items(), key=lambda x: x[1]['r2'], reverse=True):
    print(f"{name:<20} ${result['rmse']:<11.2f} ${result['mae']:<11.2f} {result['r2']:<12.4f} {result['cv_mean']:.4f} (+/- {result['cv_std']:.4f})")

# Melhor modelo
best_model_name = max(results, key=lambda x: results[x]['r2'])
best_model = results[best_model_name]['model']
best_predictions = results[best_model_name]['predictions']

print(f"\nüèÜ Melhor modelo: {best_model_name}")
print(f"üéØ R¬≤ Score: {results[best_model_name]['r2']:.4f}")
print(f"üéØ RMSE: ${results[best_model_name]['rmse']:.2f}")
print(f"üéØ MAE: ${results[best_model_name]['mae']:.2f}")

# An√°lise de res√≠duos
residuals = y_test - best_predictions
print(f"\nüìä An√°lise de Res√≠duos ({best_model_name}):")
print("-" * 60)
print(f"M√©dia dos res√≠duos: ${residuals.mean():.2f}")
print(f"Desvio padr√£o dos res√≠duos: ${residuals.std():.2f}")
print(f"Res√≠duo m√≠nimo: ${residuals.min():.2f}")
print(f"Res√≠duo m√°ximo: ${residuals.max():.2f}")

# Coeficientes do modelo
print(f"\nüìä Coeficientes do Modelo ({best_model_name}):")
print("-" * 60)
coef_df = pd.DataFrame({
    'Feature': features_to_use,
    'Coeficiente': best_model.coef_
}).sort_values('Coeficiente', key=abs, ascending=False)
print(coef_df.to_string(index=False))
print(f"\nIntercepto: ${best_model.intercept_:.2f}")

# ==========================
# 7. PREDI√á√ïES DE EXEMPLO
# ==========================
print("\n" + "=" * 60)
print("EXEMPLOS DE PREDI√á√ÉO")
print("=" * 60)

# Mostrar alguns exemplos de predi√ß√£o
examples = X_test.head(10)
examples_scaled = scaler.transform(examples)
predictions = best_model.predict(examples_scaled)

print("\nPrimeiros 10 passageiros do conjunto de teste:")
print("-" * 80)
print(f"{'Real':<12} {'Predito':<12} {'Erro':<12} {'Classe':<8} {'Sexo':<8} {'Idade':<8}")
print("-" * 80)
for i in range(len(examples)):
    real = y_test.iloc[i]
    pred = predictions[i]
    erro = abs(real - pred)
    print(f"${real:<11.2f} ${pred:<11.2f} ${erro:<11.2f} {examples.iloc[i]['Pclass']:<8} {examples.iloc[i]['Sex']:<8} {examples.iloc[i]['Age']:<8.0f}")

# ==========================
# 8. EXPORTAR O MODELO
# ==========================
print("\n" + "=" * 60)
print("EXPORTAR MODELO E SCALER")
print("=" * 60)

import joblib

# Exportar o melhor modelo
joblib.dump(best_model, 'modelo_titanic.pkl')
print(f"‚úÖ Modelo exportado: modelo_titanic.pkl")

# Exportar o scaler
joblib.dump(scaler, 'scaler_titanic.pkl')
print(f"‚úÖ Scaler exportado: scaler_titanic.pkl")

# Exportar informa√ß√µes adicionais
model_info = {
    'model_name': best_model_name,
    'features': features_to_use,
    'r2_score': results[best_model_name]['r2'],
    'rmse': results[best_model_name]['rmse'],
    'mae': results[best_model_name]['mae']
}
joblib.dump(model_info, 'model_info.pkl')
print(f"‚úÖ Informa√ß√µes do modelo exportadas: model_info.pkl")

print("\nüí° Para carregar o modelo depois:")
print("   modelo = joblib.load('modelo_titanic.pkl')")
print("   scaler = joblib.load('scaler_titanic.pkl')")
print("   info = joblib.load('model_info.pkl')")

# ==========================
# 9. CONCLUS√ïES
# ==========================
print("\n" + "=" * 60)
print("CONCLUS√ïES")
print("=" * 60)
print(f"""
‚úÖ Modelo de regress√£o treinado com sucesso!
üéØ Melhor modelo: {best_model_name}
üìä R¬≤ Score: {results[best_model_name]['r2']:.4f}
üìä RMSE: ${results[best_model_name]['rmse']:.2f}
üìä MAE: ${results[best_model_name]['mae']:.2f}
üîç Total de passageiros analisados: {len(df_processed)}
üìà Cross-validation R¬≤: {results[best_model_name]['cv_mean']:.4f}

üí° O modelo pode prever a tarifa (Fare) paga por um passageiro
   com base em caracter√≠sticas como classe, sexo, idade, fam√≠lia
   e status de sobreviv√™ncia.
   
üìå Interpreta√ß√£o do R¬≤: {results[best_model_name]['r2']*100:.2f}% da variabilidade
   da tarifa √© explicada pelo modelo.
""")

print("=" * 60)
print("AN√ÅLISE CONCLU√çDA!")
print("=" * 60)